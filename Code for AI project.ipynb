{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_D1OADRBMFB4"
   },
   "source": [
    "This notebook is used to compile all our models and compare them along with some standardized format. Make sure your code output fits as input to this standardized format, such that it only needs to be imported and can run from the get-go.\n",
    "\n",
    "I'll also build some plotter to make this work well and of course ensure there is proper docstrings and comments\n",
    "\n",
    "(If you want to make your folder importable, like I did with Code_Emiel, simply add an empty __init__.py to the folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard format\n",
    "\n",
    "from typing import List\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "class StandardFormat:\n",
    "    def __init__(self, n_samples):\n",
    "        self.detected_outliers = {}\n",
    "        self.confidences = {}\n",
    "        self.n_samples = n_samples\n",
    "\n",
    "    def add_outlier_samples(self, model_name: str, outliers: List[str]):\n",
    "        \"\"\"\n",
    "        model_name: str = the name of your model of which you want to add the outliers to the pool\n",
    "\n",
    "        outliers: list = the list of sample/measurement names (don't add anything else besides that, just the names of the samples (sample_1, sample_4567, etc)) (the length of the list doesn't matter, it can be any length, ensuring the alpha is 0.05)\n",
    "\n",
    "        Call this function to add identified samples to the data pool\n",
    "        With that I mean the following:\n",
    "        with a certain alpha value, you select which samples are identified to be outliers.\n",
    "\n",
    "        For this alpha, make sure you take 0.05! (standard alpha value)\n",
    "\n",
    "        This is important, else we're comparing apples with oranges.\n",
    "        \"\"\"\n",
    "        \n",
    "        assert all(isinstance(item, str) for item in outliers), \"Outliers should be a list of strings\"\n",
    "        self.detected_outliers.update({model_name: outliers})\n",
    "\n",
    "    def add_confidences(self, model_name: str, confidences: List[(str, float)]):\n",
    "        \"\"\"\n",
    "        model_name: str = the name of your model of which you want to add the confidences to the pool\n",
    "\n",
    "        confidences: list = the list of (sample_name, confidence values) (probabilities between 0 and 1 that this sample or measurement is an outlier) (don't add anything else besides that, just the confidence values)\n",
    "\n",
    "        Call this function to add identified samples to the data pool\n",
    "        We're specifically NOT working with alpha values in this one\n",
    "        Ensure that the raw confidence values of something being an outlier are added here\n",
    "        What is the confidence value? A probability between 0 and 1 that this sample or measurement is an outlier, with 1 being fully confident that it IS an outlier, and vice versa.\n",
    "    \n",
    "        Ensure that the length of the confidences list is the same as the length of the entire dataset (so make sure that all samples are in the list, and nothing more or less. I will assert this, it will crash if the length is off!).\n",
    "        \"\"\"\n",
    "        if self.n_samples is not None and len(confidences) != self.n_samples:\n",
    "            raise ValueError(f\"Expected {self.n_samples} confidences, got {len(confidences)}\")\n",
    "        self.confidences.update({model_name: confidences})\n",
    "\n",
    "    def compute_similarity_scores_detected_outliers(self, plot_results: bool = False):\n",
    "        models = list(self.detected_outliers)\n",
    "        M = len(models)\n",
    "        matrix = np.zeros((M, M), dtype=float)\n",
    "\n",
    "        for i, model_name in enumerate(models):\n",
    "            si = set(self.detected_outliers[model_name])\n",
    "            for j, other_model_name in enumerate(models):\n",
    "                if i == j:\n",
    "                    matrix[i, j] = np.nan  # Diagonal can be set to NaN or 0 as preferred\n",
    "                else:\n",
    "                    sj = set(self.detected_outliers[other_model_name])\n",
    "                    union = len(si | sj)\n",
    "                    matrix[i, j] = (len(si & sj) / union) if union else np.nan\n",
    "\n",
    "        if plot_results:\n",
    "            fig, ax = plt.subplots()\n",
    "            cax = ax.imshow(matrix, cmap='viridis', interpolation='nearest')\n",
    "            fig.colorbar(cax, ax=ax)\n",
    "            ax.set_xticks(range(M))\n",
    "            ax.set_xticklabels(models, rotation=90)\n",
    "            ax.set_yticks(range(M))\n",
    "            ax.set_yticklabels(models)\n",
    "            ax.set_title(\"Similarity Matrix of Detected Outliers\", pad=20)\n",
    "            plt.show()\n",
    "        return models, matrix\n",
    "\n",
    "    def compute_similarity_scores_confidences(self, plot_results: bool = False):\n",
    "        models = list(self.confidences)\n",
    "        sorted_confidences = {\n",
    "            m: sorted(self.confidences[m], key=lambda x: x[0])\n",
    "            for m in models\n",
    "        }\n",
    "        X = np.vstack([\n",
    "            [conf for (_sid, conf) in sorted_confidences[m]]\n",
    "            for m in models\n",
    "        ])\n",
    "        matrix = cosine_similarity(X)\n",
    "        np.fill_diagonal(matrix, np.nan)\n",
    "\n",
    "        if plot_results:\n",
    "            fig, ax = plt.subplots(figsize=(6,6))\n",
    "            cax = ax.imshow(matrix, cmap='viridis', interpolation='nearest')\n",
    "            fig.colorbar(cax, ax=ax)\n",
    "            ax.set_xticks(range(len(models)))\n",
    "            ax.set_xticklabels(models, rotation=90)\n",
    "            ax.set_yticks(range(len(models)))\n",
    "            ax.set_yticklabels(models)\n",
    "            ax.set_title(\"Similarity Matrix of Confidences\", pad=20)\n",
    "            plt.show()\n",
    "        return models, matrix\n",
    "\n",
    "standard_format = StandardFormat(20446)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wyH05nBUN1cS"
   },
   "source": [
    "**Emiel's code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "error",
     "timestamp": 1747170045635,
     "user": {
      "displayName": "Emiel Nagel",
      "userId": "01626522335705697756"
     },
     "user_tz": -120
    },
    "id": "XPS0t5SIL9DQ",
    "outputId": "fc911ae0-368a-4c86-ee28-23d6096b9a76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18548, 51)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got scalar array instead:\narray=0.05.\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mCode_Emiel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Elliptic_Envelope \u001b[38;5;28;01mas\u001b[39;00m elliptic_envelope_emiel\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mCode_Emiel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Robust_PCA \u001b[38;5;28;01mas\u001b[39;00m rpca_emiel\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m outliers, confidences = \u001b[43melliptic_envelope_emiel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m standard_format.add_outlier_samples(\u001b[33m\"\u001b[39m\u001b[33mElliptic Envelope Emiel\u001b[39m\u001b[33m\"\u001b[39m, outliers)\n\u001b[32m      6\u001b[39m standard_format.add_confidences(\u001b[33m\"\u001b[39m\u001b[33mElliptic Envelope Emiel\u001b[39m\u001b[33m\"\u001b[39m, confidences)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Emiel\\Documents\\Study\\AI\\AI_in_the_Professional_Workfield\\Project\\AI-in-the-Professional-Workfield-Code\\Code_Emiel\\Elliptic_Envelope.py:60\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     56\u001b[39m squared_distances = outlier_detector.decision_function(features)\n\u001b[32m     59\u001b[39m \u001b[38;5;66;03m# Detect outliers in the dataset\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m outlier_names, confidences, pct = \u001b[43mdetect_outliers\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutlier_detector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(outlier_names)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m outliers (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpct\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m% of samples):\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     62\u001b[39m \u001b[38;5;28mprint\u001b[39m(outlier_names)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Emiel\\Documents\\Study\\AI\\AI_in_the_Professional_Workfield\\Project\\AI-in-the-Professional-Workfield-Code\\Code_Emiel\\Elliptic_Envelope.py:24\u001b[39m, in \u001b[36mdetect_outliers\u001b[39m\u001b[34m(outlier_detector, sample_names, features, alpha)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdetect_outliers\u001b[39m(outlier_detector, sample_names, features, alpha=\u001b[32m0.05\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     squared_distances = \u001b[43moutlier_detector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m     distances = np.sqrt(np.abs(squared_distances))  \u001b[38;5;66;03m# Convert to distances\u001b[39;00m\n\u001b[32m     26\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mMax:\u001b[39m\u001b[33m\"\u001b[39m, np.max(distances), \u001b[33m\"\u001b[39m\u001b[33mMin:\u001b[39m\u001b[33m\"\u001b[39m, np.min(distances))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Emiel\\Documents\\Study\\AI\\AI_in_the_Professional_Workfield\\Project\\AI-in-the-Professional-Workfield-Code\\.venv\\Lib\\site-packages\\sklearn\\covariance\\_elliptic_envelope.py:204\u001b[39m, in \u001b[36mEllipticEnvelope.decision_function\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    188\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Compute the decision function of the given observations.\u001b[39;00m\n\u001b[32m    189\u001b[39m \n\u001b[32m    190\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    201\u001b[39m \u001b[33;03m    compatibility with other outlier detection algorithms.\u001b[39;00m\n\u001b[32m    202\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    203\u001b[39m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m204\u001b[39m negative_mahal_dist = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscore_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m negative_mahal_dist - \u001b[38;5;28mself\u001b[39m.offset_\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Emiel\\Documents\\Study\\AI\\AI_in_the_Professional_Workfield\\Project\\AI-in-the-Professional-Workfield-Code\\.venv\\Lib\\site-packages\\sklearn\\covariance\\_elliptic_envelope.py:221\u001b[39m, in \u001b[36mEllipticEnvelope.score_samples\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Compute the negative Mahalanobis distances.\u001b[39;00m\n\u001b[32m    209\u001b[39m \n\u001b[32m    210\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    218\u001b[39m \u001b[33;03m    Opposite of the Mahalanobis distances.\u001b[39;00m\n\u001b[32m    219\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    220\u001b[39m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m -\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmahalanobis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Emiel\\Documents\\Study\\AI\\AI_in_the_Professional_Workfield\\Project\\AI-in-the-Professional-Workfield-Code\\.venv\\Lib\\site-packages\\sklearn\\covariance\\_empirical_covariance.py:358\u001b[39m, in \u001b[36mEmpiricalCovariance.mahalanobis\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmahalanobis\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m    344\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute the squared Mahalanobis distances of given observations.\u001b[39;00m\n\u001b[32m    345\u001b[39m \n\u001b[32m    346\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    356\u001b[39m \u001b[33;03m        Squared Mahalanobis distances of the observations.\u001b[39;00m\n\u001b[32m    357\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m358\u001b[39m     X = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    360\u001b[39m     precision = \u001b[38;5;28mself\u001b[39m.get_precision()\n\u001b[32m    361\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(assume_finite=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m    362\u001b[39m         \u001b[38;5;66;03m# compute mahalanobis distances\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Emiel\\Documents\\Study\\AI\\AI_in_the_Professional_Workfield\\Project\\AI-in-the-Professional-Workfield-Code\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2944\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2942\u001b[39m         out = X, y\n\u001b[32m   2943\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[32m-> \u001b[39m\u001b[32m2944\u001b[39m     out = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2945\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[32m   2946\u001b[39m     out = _check_y(y, **check_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Emiel\\Documents\\Study\\AI\\AI_in_the_Professional_Workfield\\Project\\AI-in-the-Professional-Workfield-Code\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1070\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1067\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_2d:\n\u001b[32m   1068\u001b[39m     \u001b[38;5;66;03m# If input is scalar raise error\u001b[39;00m\n\u001b[32m   1069\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m array.ndim == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1070\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1071\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mExpected 2D array, got scalar array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33marray=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1072\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1073\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1074\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mif it contains a single sample.\u001b[39m\u001b[33m\"\u001b[39m.format(array)\n\u001b[32m   1075\u001b[39m         )\n\u001b[32m   1076\u001b[39m     \u001b[38;5;66;03m# If input is 1D raise error\u001b[39;00m\n\u001b[32m   1077\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m array.ndim == \u001b[32m1\u001b[39m:\n\u001b[32m   1078\u001b[39m         \u001b[38;5;66;03m# If input is a Series-like object (eg. pandas Series or polars Series)\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: Expected 2D array, got scalar array instead:\narray=0.05.\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "from Code_Emiel import Elliptic_Envelope as elliptic_envelope_emiel\n",
    "from Code_Emiel import Robust_PCA as rpca_emiel\n",
    "\n",
    "outliers, confidences = elliptic_envelope_emiel.main()\n",
    "standard_format.add_outlier_samples(\"Elliptic Envelope Emiel\", outliers)\n",
    "standard_format.add_confidences(\"Elliptic Envelope Emiel\", confidences)\n",
    "\n",
    "outliers, confidences = rpca_emiel.main()\n",
    "standard_format.add_outlier_samples(\"Robust PCA Emiel\", outliers)\n",
    "standard_format.add_confidences(\"Robust PCA Emiel\", confidences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nicolas' code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Abhinav's code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jd2OLiCwOCgZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Patricia's code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_format.compute_similarity_scores_detected_outliers(plot_results=True)\n",
    "standard_format.compute_similarity_scores_confidences(plot_results=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOIZibouf6EILUS6jXpZ9Bd",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
